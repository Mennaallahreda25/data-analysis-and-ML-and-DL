{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Financial Data - Pandas Datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "This time you will get data from a website.\n",
    "\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:06:37.710558Z",
     "start_time": "2022-11-25T22:06:37.372840Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create your time range (start and end variables). The start date should be 01/01/2015 and the end should today (whatever your today is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:13:49.686498Z",
     "start_time": "2022-11-25T22:13:49.615678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3369: UserWarning: Parsing '26-11-2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "time = pd.date_range(\"01-01-2017\",\"26-11-2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:14:01.478914Z",
     "start_time": "2022-11-25T22:14:01.458969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n",
       "               '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n",
       "               '2017-01-09', '2017-01-10',\n",
       "               ...\n",
       "               '2022-11-17', '2022-11-18', '2022-11-19', '2022-11-20',\n",
       "               '2022-11-21', '2022-11-22', '2022-11-23', '2022-11-24',\n",
       "               '2022-11-25', '2022-11-26'],\n",
       "              dtype='datetime64[ns]', length=2156, freq='D')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Get an API key for one of the APIs that are supported by Pandas Datareader, preferably for AlphaVantage.\n",
    "\n",
    "If you do not have an API key for any of the supported APIs, it is easiest to get one for [AlphaVantage](https://www.alphavantage.co/support/#api-key). (Note that the API key is shown directly after the signup. You do *not* receive it via e-mail.)\n",
    "\n",
    "(For a full list of the APIs that are supported by Pandas Datareader, [see here](https://pydata.github.io/pandas-datareader/readers/index.html). As the APIs are provided by third parties, this list may change.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " API key: 093QDBKYAUQCF8R7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Use Pandas Datarader to read the daily time series for the Apple stock (ticker symbol AAPL) between 01/01/2015 and today, assign it to df_apple and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:32:28.990979Z",
     "start_time": "2022-11-25T22:32:06.061580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-datareader\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas-datareader) (4.8.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.27.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas-datareader) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-datareader) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.3)\n",
      "Installing collected packages: pandas-datareader\n",
      "Successfully installed pandas-datareader-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T22:32:56.425831Z",
     "start_time": "2022-11-25T22:32:55.453913Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:24:10.634254Z",
     "start_time": "2022-11-25T23:24:08.745364Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\pandas_datareader\\_utils.py:37: UserWarning: Parsing '26/11/2022' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  end = to_datetime(end)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  High         Low        Open       Close       Volume  \\\n",
      "Date                                                                      \n",
      "2015-01-02   14.883333   14.217333   14.858000   14.620667   71466000.0   \n",
      "2015-01-05   14.433333   13.810667   14.303333   14.006000   80527500.0   \n",
      "2015-01-06   14.280000   13.614000   14.004000   14.085333   93928500.0   \n",
      "2015-01-07   14.318667   13.985333   14.223333   14.063333   44526000.0   \n",
      "2015-01-08   14.253333   14.000667   14.187333   14.041333   51637500.0   \n",
      "...                ...         ...         ...         ...          ...   \n",
      "2022-11-18  185.190002  176.550003  185.050003  180.190002   75904900.0   \n",
      "2022-11-21  176.770004  167.539993  175.850006  167.869995   92882700.0   \n",
      "2022-11-22  170.919998  166.190002  168.630005  169.910004   78452300.0   \n",
      "2022-11-23  183.619995  172.500000  173.570007  183.199997  109536700.0   \n",
      "2022-11-25  185.184998  180.639999  185.059998  182.860001   50247676.0   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2015-01-02   14.620667  \n",
      "2015-01-05   14.006000  \n",
      "2015-01-06   14.085333  \n",
      "2015-01-07   14.063333  \n",
      "2015-01-08   14.041333  \n",
      "...                ...  \n",
      "2022-11-18  180.190002  \n",
      "2022-11-21  167.869995  \n",
      "2022-11-22  169.910004  \n",
      "2022-11-23  183.199997  \n",
      "2022-11-25  182.860001  \n",
      "\n",
      "[1990 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df_apple = web.DataReader(name=\"TSLA\", data_source='yahoo', start='01/01/2015', end='26/11/2022')\n",
    "print(df_apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Add a new column \"stock\" to the dataframe and add the ticker symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:45:03.791037Z",
     "start_time": "2022-11-25T23:45:03.775052Z"
    }
   },
   "outputs": [],
   "source": [
    "stock =pd.Series(['AAPL']).repeat(2156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Repeat the two previous steps for a few other stocks, always creating a new dataframe: Tesla, IBM and Microsoft. (Ticker symbols TSLA, IBM and MSFT.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:45:06.943872Z",
     "start_time": "2022-11-25T23:45:06.923926Z"
    }
   },
   "outputs": [],
   "source": [
    "Tesla=pd.Series(['TSLA']).repeat(2156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:45:07.721297Z",
     "start_time": "2022-11-25T23:45:07.712318Z"
    }
   },
   "outputs": [],
   "source": [
    "IBM=pd.Series(['IBM']).repeat(2156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:45:08.230018Z",
     "start_time": "2022-11-25T23:45:08.216055Z"
    }
   },
   "outputs": [],
   "source": [
    "Microsoft=pd.Series(['MSFT']).repeat(2156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Combine the four separate dataFrames into one combined dataFrame df that holds the information for all four stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:46:01.855776Z",
     "start_time": "2022-11-25T23:46:01.838823Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.concat([time, Tesla, IBM, Microsoft])\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Shift the stock column into the index (making it a multi-level index consisting of the ticker symbol and the date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['time','Tesla', 'IBM', 'Microsoft'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Create a dataFrame called vol, with the volume values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[vol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Aggregate the data of volume to weekly.\n",
    "Hint: Be careful to not sum data from the same week of 2015 and other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:46:29.165988Z",
     "start_time": "2022-11-25T23:46:29.150030Z"
    }
   },
   "outputs": [],
   "source": [
    "time.resample('W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. Find all the volume traded in the year of 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T23:39:38.280386Z",
     "start_time": "2022-11-25T23:39:38.262436Z"
    }
   },
   "outputs": [],
   "source": [
    "time['2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
